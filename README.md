# ğŸ§  Job Data Warehouse

## 1ï¸âƒ£ Overview
This project implements a **Medallion Data Warehouse architecture** (Bronze â†’ Silver â†’ Gold) to build an automated data pipeline.

Data is **crawled from TopCV**, stored in **PostgreSQL**, and orchestrated by **Apache Airflow**.  
The purpose is to analyze job trends â€” including the most demanded **skills**, **programming languages**, and **positions** in the market.

---

### âš™ï¸ Tech Stack

| Component | Description |
|------------|-------------|
| **Apache Airflow** | Orchestrates and schedules the ETL/ELT pipeline |
| **PostgreSQL** | Stores data in bronze, silver, and gold schemas |
| **Python** | Extracts, cleans, and transforms job data |
| **Docker Compose** | Sets up the entire environment easily |

---

## 2ï¸âƒ£ How to Run

1. **Initialize Airflow environment**
```bash
   docker compose up airflow-init
   docker compose up -d
```
2. **Folder structure**
```bash
â”œâ”€â”€ config/
â”‚   â””â”€â”€ airflow.cfg                     # Airflow config file
â”œâ”€â”€ logs/                               # Task logs
â”œâ”€â”€ plugins/                            # Airflow plugins (if any)
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ ELT.py                          # Main DAG pipeline
â”‚   â”œâ”€â”€ logger.py                       # Logging setup
â”‚   â”œâ”€â”€ mapping.py                      # Helper mapping script
â”‚   â”œâ”€â”€ extract/
â”‚   â”‚   â””â”€â”€ extract.py                  # Crawl job data from TopCV
â”‚   â”œâ”€â”€ transform/
â”‚   â”‚   â””â”€â”€ transform.py                # Data cleaning and standardization
â”‚   â””â”€â”€ load/
â”‚       â”œâ”€â”€ load_bronze.py              # Load raw data into bronze schema
â”‚       â”œâ”€â”€ load_silver.py              # Process and load silver data
â”‚       â””â”€â”€ load_gold.py                # Build final fact & dimension tables
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ init_database.sql               # Initialize DB schemas and tables
â”‚   â”œâ”€â”€ dim_*.sql                       # Dimension tables (location, skill, etc.)
â”‚   â”œâ”€â”€ fact_*.sql                      # Fact tables
â”‚   â””â”€â”€ bridge_*.sql                    # Bridge (many-to-many) tables
â”œâ”€â”€ docker-compose.yaml                 # Docker environment setup
â”œâ”€â”€ .env                                # Environment variables (Postgres, Airflow)
â””â”€â”€ README.md
